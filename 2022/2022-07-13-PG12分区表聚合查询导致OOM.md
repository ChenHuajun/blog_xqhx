# PG12分区表聚合查询导致OOM

## 1. 问题
最近遇到一个很问题，PG 12上对分区表执行一个非常简单的聚合查询就到数据库OOM重启。

下面是复现这个问题的例子：

*建表和初始化数据*
```
CREATE TABLE tbpart (
    id         int,
    c1         int
) PARTITION BY HASH (c1);


create table tbpart_0 partition of tbpart for values with (MODULUS  4,remainder 0);
create table tbpart_1 partition of tbpart for values with (MODULUS  4,remainder 1);
create table tbpart_2 partition of tbpart for values with (MODULUS  4,remainder 2);
create table tbpart_3 partition of tbpart for values with (MODULUS  4,remainder 3);

insert into tbpart select id,id from generate_series(1,50000000)id;
```

*执行查询*
```
postgres=# set max_parallel_workers_per_gather =0;
SET
postgres=# select id,count(*) from tbpart group by id;
ERROR:  out of memory
DETAIL:  Failed on request of size 1610612736 in memory context "ExecutorState".
```
注：为了简化上面关闭了并行查询，开并行一样会触发OOM。


## 2. 原因

提了一个BUG到社区，tom lane答复如下：

https://www.postgresql.org/message-id/flat/17548-4d206a94ee58f3a5%40postgresql.org
```
This is resolved in PG v13 and later.  In older versions, it's
advisable to do an explicit ANALYZE on a large table, so that the
planner knows that the number of groups is large and will avoid
trying to do a hash aggregation.
```

解释一下
1. PG12及以前的版本，hash聚合的hash表放在内存里，唯一值数量过大，会导致OOM。
2. 手动ANALYZE更新统计信息可以让优化器避免hash聚合
3. PG13以后hash表如果过大，可以落盘，不会出现这个问题（已验证）。


这里有一个疑问，为什么普通表没事，分区表有问题?
```
postgres=# explain select id,count(*) from tbpart_0 group by id;
                                   QUERY PLAN
--------------------------------------------------------------------------------
 GroupAggregate  (cost=1995424.28..2214158.63 rows=12499106 width=12)
   Group Key: id
   ->  Sort  (cost=1995424.28..2026672.04 rows=12499106 width=4)
         Sort Key: id
         ->  Seq Scan on tbpart_0  (cost=0.00..180297.06 rows=12499106 width=4)
(5 rows)

postgres=# explain select id,count(*) from tbpart group by id;
                                   QUERY PLAN
--------------------------------------------------------------------------------
 HashAggregate  (cost=1221241.68..1221243.68 rows=200 width=12)
   Group Key: tbpart_0.id
   ->  Append  (cost=0.00..971241.51 rows=50000034 width=4)
         ->  Seq Scan on tbpart_0  (cost=0.00..180297.06 rows=12499106 width=4)
         ->  Seq Scan on tbpart_1  (cost=0.00..180339.38 rows=12501938 width=4)
         ->  Seq Scan on tbpart_2  (cost=0.00..180284.52 rows=12498252 width=4)
         ->  Seq Scan on tbpart_3  (cost=0.00..180320.38 rows=12500738 width=4)
(7 rows)
```

根据上面的执行计划，可以明显看出对分区表的hash聚合结果集出现了巨大的偏差，估算只有200行，实际4个分区加起来应该是5000w行。
检查分区表的统计信息是空的，手动执行ANALYZE后，统计信息中才有了值。
```
postgres=# select * from pg_stats where tablename = 'tbpart';
(0 rows)
postgres=# analyze tbpart;
ANALYZE
postgres=# select * from pg_stats where tablename = 'tbpart';
-[ RECORD 1 ]----------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
schemaname             | public
tablename              | tbpart
attname                | id
inherited              | t
null_frac              | 0
avg_width              | 4
n_distinct             | -1
most_common_vals       |
most_common_freqs      |
histogram_bounds       | {1242,563476,1043923,1527759,2050749,2604447,3032675,3520610,3990601,4505866,4978386,5478792,6022209,6541522,6990396,7461208,7997389,8514766,9039461,9510564,9987710,10400470,10910818,11464488,11994787,12545538,13043447,13530244,14053142,14586811,15159407,15661805,16267936,16748836,17226974,17729966,18187025,18657669,19154472,19563953,20045316,20524258,20998457,21573871,22073792,22539188,23004170,23508249,23987474,24444924,24932012,25511839,25951126,26401575,26893843,27435199,28052837,28470144,28998098,29470961,29963972,30494433,31014807,31473934,32018481,32529719,32997652,33476954,33987395,34487415,35013920,35511183,36000685,36532145,37047879,37588187,38042772,38535874,39121281,39625641,40157679,40613659,41151054,41581287,42077730,42544446,43012765,43521187,43976676,44488511,45024365,45531142,46043120,46486974,46994411,47524262,48044327,48567090,49012642,49471229,49997957}
correlation            | 0.2544974
most_common_elems      |
most_common_elem_freqs |
elem_count_histogram   |
```

手动执行ANALYZE后，执行计划也改成Group聚合了。
```
postgres=# explain select id,count(*) from tbpart group by id;
                                      QUERY PLAN
--------------------------------------------------------------------------------------
 GroupAggregate  (cost=9415928.41..10290932.40 rows=50000228 width=12)
   Group Key: tbpart_0.id
   ->  Sort  (cost=9415928.41..9540928.98 rows=50000228 width=4)
         Sort Key: tbpart_0.id
         ->  Append  (cost=0.00..971244.42 rows=50000228 width=4)
               ->  Seq Scan on tbpart_0  (cost=0.00..180297.56 rows=12499156 width=4)
               ->  Seq Scan on tbpart_1  (cost=0.00..180343.20 rows=12502320 width=4)
               ->  Seq Scan on tbpart_2  (cost=0.00..180282.14 rows=12498014 width=4)
               ->  Seq Scan on tbpart_3  (cost=0.00..180320.38 rows=12500738 width=4)
(9 rows)
```

查阅PG手册，发现手册中已有说明，分区表的统计信息更新必须手动触发。

https://www.postgresql.org/docs/12/routine-vacuuming.html
```
Tuples changed in partitions and inheritance children do not trigger analyze on the parent table. 
If the parent table is empty or rarely changed, it may never be processed by autovacuum, and the 
statistics for the inheritance tree as a whole won't be collected. It is necessary to run ANALYZE
 on the parent table manually in order to keep the statistics up to date.
```

## 3. 总结

分区表必须及时手动ANALYZE，不光是为了回避本件的OOM问题，统计信息不准还会招致各种性能糟糕的执行计划。
