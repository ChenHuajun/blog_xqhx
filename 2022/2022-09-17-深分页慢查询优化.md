## 概述

应用页面中展示查询结果时，如果结果数据量很大，一般会分页展示。
分页显示时，如果处理不好，容易出现慢SQL。
比如,下面这篇文章展示的深分页导致的慢SQL。
- [整整修了6个小时，一次难料的分页慢查询事故……](https://dbaplus.cn/news-160-4784-1.html)

虽然这个案例是MySQL，但原理是相通的，下面以PostgreSQL为例，演示一下深分页相关的优化方法。

## 示例

### 创建测试表
```
create table tb1(id int,c1 int,c2 int);
insert into tb1 select id,random()*1000,random()*1000 from generate_series(1,10000000)id;
create index tb1_id_idx on tb1(id);
create index tb1_id_c1 on tb1(c1);
```

### 原始SQL（14ms）
explain analyze
select * from tb1 where c1 = 888 offset 5000 limit 100;

```
postgres=# explain analyze
select * from tb1 where c1 = 888 offset 5000 limit 100;
                                                           QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=12858.12..13113.02 rows=100 width=12) (actual time=13.617..13.849 rows=100 loops=1)
   ->  Bitmap Heap Scan on tb1  (cost=113.42..25432.05 rows=9933 width=12) (actual time=5.093..13.519 rows=5100 loops=1)
         Recheck Cond: (c1 = 888)
         Heap Blocks: exact=4660
         ->  Bitmap Index Scan on tb1_id_c1  (cost=0.00..110.93 rows=9933 width=0) (actual time=2.520..2.520 rows=9805 loops=1)
               Index Cond: (c1 = 888)
 Planning Time: 0.109 ms
 Execution Time: 13.885 ms
(8 rows)
```

### 先查id再回表（2ms）

对于示例的深分页，前面的5000记录都是要跳过。原始SQL的执行计划中对这5000条记录都要回表，回表消耗了比较多的时间，那么是否可以先在c1字段索引上把这5000条记录跳过，避免回表呢。

尝试使用下面的方法,先查出ctid，再回表。
```
postgres=# explain analyze
select * from tb1 where
ctid in (select ctid from tb1 where c1 = 888 offset 5000 limit 100);
                                                                 QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=13113.27..13516.52 rows=100 width=12) (actual time=14.999..15.152 rows=100 loops=1)
   ->  HashAggregate  (cost=13113.27..13114.27 rows=100 width=6) (actual time=14.979..14.999 rows=100 loops=1)
         Group Key: tb1_1.ctid
         Batches: 1  Memory Usage: 24kB
         ->  Limit  (cost=12858.12..13113.02 rows=100 width=6) (actual time=14.754..14.925 rows=100 loops=1)
               ->  Bitmap Heap Scan on tb1 tb1_1  (cost=113.42..25432.05 rows=9933 width=6) (actual time=5.960..14.583 rows=5100 loops=1)
                     Recheck Cond: (c1 = 888)
                     Heap Blocks: exact=4660
                     ->  Bitmap Index Scan on tb1_id_c1  (cost=0.00..110.93 rows=9933 width=0) (actual time=2.926..2.926 rows=9805 loops=1)
                           Index Cond: (c1 = 888)
   ->  Tid Scan on tb1  (cost=0.00..4.01 rows=1 width=18) (actual time=0.001..0.001 rows=1 loops=100)
         TID Cond: (ctid = tb1_1.ctid)
 Planning Time: 0.414 ms
 Execution Time: 15.233 ms
(14 rows)
```
但是，遗憾的是，`select ctid from ...`不支持index only scan, 查询ctid的时候也需要回表recheck，修改后性能没有提升。

于是创建一个带id的覆盖索引
```
create index tb1_id_c1_id on tb1(c1) include (id);
```

然后，先查id，再回表，此时性能优化到2ms。
```
postgres=# explain analyze
select * from tb1 where
id in (select id from tb1 where c1 = 888 offset 5000 limit 100);
                                                                      QUERY PLAN
-------------------------------------------------------------------------------------------------------------------------------------------------------
 Nested Loop  (cost=147.88..994.69 rows=100 width=12) (actual time=1.527..2.139 rows=100 loops=1)
   ->  HashAggregate  (cost=147.44..148.44 rows=100 width=4) (actual time=1.512..1.532 rows=100 loops=1)
         Group Key: tb1_1.id
         Batches: 1  Memory Usage: 24kB
         ->  Limit  (cost=144.31..147.19 rows=100 width=4) (actual time=1.446..1.474 rows=100 loops=1)
               ->  Index Only Scan using tb1_id_c1_id on tb1 tb1_1  (cost=0.43..286.26 rows=9933 width=4) (actual time=0.015..1.233 rows=5100 loops=1)
                     Index Cond: (c1 = 888)
                     Heap Fetches: 0
   ->  Index Scan using tb1_id_idx on tb1  (cost=0.43..8.45 rows=1 width=12) (actual time=0.005..0.006 rows=1 loops=100)
         Index Cond: (id = tb1_1.id)
 Planning Time: 0.273 ms
 Execution Time: 2.181 ms
(12 rows)
```

### 滚动id（0.2ms）
在禁止用户跳跃分页的情况下，可以对结果按id排序，并缓存上次获取的最大id值，作为条件代入下次查询中（`id > 5057602`），避免offset。

```
postgres=# explain analyze
select * from tb1 where c1 = 888 and id > 5057602 order by id limit 100;
                                                            QUERY PLAN
----------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.43..3661.97 rows=100 width=12) (actual time=0.320..35.546 rows=100 loops=1)
   ->  Index Scan using tb1_id_idx on tb1  (cost=0.43..179781.83 rows=4910 width=12) (actual time=0.318..35.524 rows=100 loops=1)
         Index Cond: (id > 5057602)
         Filter: (c1 = 888)
         Rows Removed by Filter: 107582
 Planning Time: 0.234 ms
 Execution Time: 35.589 ms
(7 rows)
```
修改后走了id索引，由于在这个SQL中走id索引效率不高，性能变差了。

结合前面“先查id再回表”的方式，再次修改SQL执行。

```
postgres=# explain analyze
select * from tb1 where
id in (select id from tb1 where c1 = 888 and id > 5057602 order by id limit 100);
                                                                         QUERY PLAN

--------------------------------------------------------------------------------------------------------------------------------------------
-----------------
 Nested Loop  (cost=434.78..1281.60 rows=100 width=12) (actual time=3.463..4.211 rows=100 loops=1)
   ->  HashAggregate  (cost=434.35..435.35 rows=100 width=4) (actual time=3.433..3.459 rows=100 loops=1)
         Group Key: tb1_1.id
         Batches: 1  Memory Usage: 24kB
         ->  Limit  (cost=433.85..434.10 rows=100 width=4) (actual time=3.362..3.381 rows=100 loops=1)
               ->  Sort  (cost=433.85..446.12 rows=4910 width=4) (actual time=3.360..3.368 rows=100 loops=1)
                     Sort Key: tb1_1.id
                     Sort Method: top-N heapsort  Memory: 25kB
                     ->  Index Only Scan using tb1_id_c1_id on tb1 tb1_1  (cost=0.43..311.10 rows=4910 width=4) (actual time=1.245..2.847 ro
ws=4805 loops=1)
                           Index Cond: (c1 = 888)
                           Filter: (id > 5057602)
                           Rows Removed by Filter: 5000
                           Heap Fetches: 0
   ->  Index Scan using tb1_id_idx on tb1  (cost=0.43..8.45 rows=1 width=12) (actual time=0.007..0.007 rows=1 loops=100)
         Index Cond: (id = tb1_1.id)
 Planning Time: 0.439 ms
 Execution Time: 4.269 ms
(17 rows)
```
执行时间变成了4ms，比前面的“先查id再回表”还慢，主要因为多了个排序。
（严格来说，前面的优化SQL也应该对id排序才能确保分页的顺序不会乱，特别是存在并发顺序扫描的扫描的时候）
MySQL中滚动id可以获得更好的优化效果，我猜测是因为滚动id的条件过滤可以下推到innodb存储层，
而offset过滤必须在SQL层执行，所以滚动id优于生offset过滤。
PostgreSQL中不存这种SQL层和存储层分离的额外负担。

前面的滚动id都没有发挥出这个方案的优势，滚动id要想生效必须在索引扫描时就确保索引记录是按id排序的，
因此创建一个c1+id的组合索引。
```
create index tb1_id_c1_id2 on tb1(c1,id);
```

```
postgres=# explain analyze
select * from tb1 where c1 = 888 and id > 5057602 order by id limit 100;
                                                            QUERY PLAN
-----------------------------------------------------------------------------------------------------------------------------------
 Limit  (cost=0.43..386.22 rows=100 width=12) (actual time=0.039..0.188 rows=100 loops=1)
   ->  Index Scan using tb1_id_c1_id2 on tb1  (cost=0.43..18942.52 rows=4910 width=12) (actual time=0.038..0.175 rows=100 loops=1)
         Index Cond: ((c1 = 888) AND (id > 5057602))
 Planning Time: 0.139 ms
 Execution Time: 0.209 ms
(5 rows)
```

### 滚动游标
前面的优化方法都依赖索引，但当查询条件不固定的时候，无法创建很多索引去适配。
考虑到用户一般不会太关心太后面的页面，特定场景下，可以用滚动游标实现。

```
BEGIN WORK;
DECLARE c1 CURSOR FOR select * from tb1 where c1 = 888
FETCH FORWARD 100 FROM c1;
FETCH FORWARD 100 FROM c1;
...
CLOSE c1;
COMMIT WORK;
```

游标通常只能在一个事务中，事务提交游标自动关闭。
我们也可以创建事务保持游标。
```
DECLARE c1 CURSOR WITH HOLD FOR select * from tb1 where c1 = 888
```
但这种游标，定义时就会把所有结果都查出来保存到临时表里,因此对于大多数场合，效率不高。
```
/home/postgres/data16pc/base/pgsql_tmp/pgsql_tmp64835.1
```
